{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import util\n",
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import awswrangler as wr\n",
    "import seaborn as sns\n",
    "from operator import attrgetter\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "model = 'schedule'\n",
    "forecastHorizon = 168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tStart = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "DATASET_FREQUENCY = \"H\" \n",
    "TIMESTAMP_FORMAT = \"yyyy-MM-dd hh:mm:ss\"\n",
    "algorithmArn = 'arn:aws:forecast:::algorithm/Deep_AR_Plus'\n",
    "# AWS setup\n",
    "region = sagemaker.Session().boto_region_name\n",
    "session = boto3.Session(region_name=region) \n",
    "forecast = session.client(service_name='forecast') \n",
    "forecastquery = session.client(service_name='forecastquery')\n",
    "# Naming\n",
    "role_arn = 'arn:aws:iam::123456:role/PuretechBillSuccessRateForecast'\n",
    "bucket_name = sagemaker.Session().default_bucket()\n",
    "key='puretech_data/' + model +'.csv'\n",
    "s3DataPath = \"s3://\"+bucket_name+\"/\"+key\n",
    "project = 'bill_scs_rate_' + model\n",
    "datasetName= project+'_ds'\n",
    "datasetGroupName= project +'_gp'\n",
    "predictorName= project+'_predictor'\n",
    "forecastName= project+'_forecast'\n",
    "forecastExportName= 'export'\n",
    "outputPath='s3://'+bucket_name+'/forecast_output/'+model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Dataset Group and Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the schema of your dataset here. Make sure the order of columns matches the raw data files.\n",
    "schema ={\n",
    "   \"Attributes\":[\n",
    "      {\n",
    "         \"AttributeName\":\"timestamp\",\n",
    "         \"AttributeType\":\"timestamp\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"item_id\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"target_value\",\n",
    "         \"AttributeType\":\"float\"\n",
    "      }\n",
    "   ]\n",
    "}\n",
    "\n",
    "response=forecast.create_dataset(\n",
    "                    Domain=\"CUSTOM\",\n",
    "                    DatasetType='TARGET_TIME_SERIES',\n",
    "                    DatasetName=datasetName,\n",
    "                    DataFrequency=DATASET_FREQUENCY, \n",
    "                    Schema = schema\n",
    "                   )\n",
    "datasetArn = response['DatasetArn']\n",
    "print(datasetArn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_group_response = forecast.create_dataset_group(DatasetGroupName=datasetGroupName,\n",
    "                                                              Domain=\"CUSTOM\",\n",
    "                                                              DatasetArns= [datasetArn]\n",
    "                                                             )\n",
    "datasetGroupArn = create_dataset_group_response['DatasetGroupArn']\n",
    "print(datasetGroupArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Import Job\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brings the data into Amazon Forecast system ready to forecast from raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetImportJobName = 'EP_DSIMPORT_JOB_TARGET'\n",
    "ds_import_job_response=forecast.create_dataset_import_job(DatasetImportJobName=datasetImportJobName,\n",
    "                                                          DatasetArn=datasetArn,\n",
    "                                                          DataSource= {\n",
    "                                                              \"S3Config\" : {\n",
    "                                                                 \"Path\":s3DataPath,\n",
    "                                                                 \"RoleArn\": role_arn\n",
    "                                                              } \n",
    "                                                          },\n",
    "                                                          TimestampFormat=TIMESTAMP_FORMAT\n",
    "                                                         )\n",
    "ds_import_job_arn=ds_import_job_response['DatasetImportJobArn']\n",
    "print(ds_import_job_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_indicator = util.StatusIndicator()\n",
    "\n",
    "while True:\n",
    "    status = forecast.describe_dataset_import_job(DatasetImportJobArn=ds_import_job_arn)['Status']\n",
    "    status_indicator.update(status)\n",
    "    if status in ('ACTIVE', 'CREATE_FAILED'): break\n",
    "    time.sleep(10)\n",
    "\n",
    "status_indicator.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Predictor with customer forecast horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_predictor_response=forecast.create_predictor(PredictorName=predictorName, \n",
    "                                                  AlgorithmArn=algorithmArn,\n",
    "                                                  ForecastHorizon=forecastHorizon,\n",
    "                                                  PerformAutoML= False,\n",
    "                                                  PerformHPO=True,\n",
    "                                                  TrainingParameters= {\"likelihood\": 'beta'},\n",
    "                                                  EvaluationParameters= {\"NumberOfBacktestWindows\": 1, \n",
    "                                                                         \"BackTestWindowOffset\": 168}, \n",
    "                                                  InputDataConfig= {\"DatasetGroupArn\": datasetGroupArn},\n",
    "                                                  FeaturizationConfig= {\"ForecastFrequency\": \"H\", \n",
    "                                                                        \"Featurizations\": \n",
    "                                                                        [\n",
    "                                                                          {\"AttributeName\": \"target_value\", \n",
    "                                                                           \"FeaturizationPipeline\": \n",
    "                                                                            [\n",
    "                                                                              {\"FeaturizationMethodName\": \"filling\", \n",
    "                                                                               \"FeaturizationMethodParameters\": \n",
    "                                                                                {\"frontfill\": \"none\", \n",
    "                                                                                 \"middlefill\": \"median\", \n",
    "                                                                                 \"backfill\": \"median\"}\n",
    "                                                                              }\n",
    "                                                                            ]\n",
    "                                                                          }\n",
    "                                                                        ]\n",
    "                                                                       }\n",
    "                                                 )\n",
    "predictorArn=create_predictor_response['PredictorArn']\n",
    "print(predictorArn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_indicator = util.StatusIndicator()\n",
    "\n",
    "while True:\n",
    "    status = forecast.describe_predictor(PredictorArn=predictorArn)['Status']\n",
    "    status_indicator.update(status)\n",
    "    if status in ('ACTIVE', 'CREATE_FAILED'): break\n",
    "    time.sleep(10)\n",
    "\n",
    "status_indicator.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.get_accuracy_metrics(PredictorArn=predictorArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_forecast_response=forecast.create_forecast(ForecastName=forecastName,\n",
    "                                                  ForecastTypes = [\"0.5\"],\n",
    "                                                  PredictorArn=predictorArn)\n",
    "forecastArn = create_forecast_response['ForecastArn']\n",
    "print(forecastArn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_indicator = util.StatusIndicator()\n",
    "\n",
    "while True:\n",
    "    status = forecast.describe_forecast(ForecastArn=forecastArn)['Status']\n",
    "    status_indicator.update(status)\n",
    "    if status in ('ACTIVE', 'CREATE_FAILED'): break\n",
    "    time.sleep(10)\n",
    "\n",
    "status_indicator.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Forecast Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_export_response = forecast.create_forecast_export_job(\n",
    "                                             ForecastExportJobName = forecastExportName,\n",
    "                                             ForecastArn = forecastArn,\n",
    "                                             Destination = {\n",
    "                                                \"S3Config\" : {\n",
    "                                                    \"Path\":outputPath,\n",
    "                                                    \"RoleArn\": role_arn\n",
    "                                                } \n",
    "                                             }\n",
    "                                           )\n",
    "forecastExportJobArn = forecast_export_response['ForecastExportJobArn']\n",
    "print(forecastExportJobArn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_indicator = util.StatusIndicator()\n",
    "\n",
    "while True:\n",
    "    status = forecast.describe_forecast_export_job(ForecastExportJobArn=forecastExportJobArn)['Status']\n",
    "    status_indicator.update(status)\n",
    "    if status in ('ACTIVE', 'CREATE_FAILED'): break\n",
    "    time.sleep(10)\n",
    "\n",
    "status_indicator.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 to DynamoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pred():\n",
    "    bucket = sagemaker.Session().default_bucket()\n",
    "    prefix = 'forecast_output/' + model \n",
    "    path = f's3://{bucket}/{prefix}'   \n",
    "    suffix = 'part0.csv'    \n",
    "    df = wr.s3.read_csv(path=path, path_suffix=suffix, last_modified_begin=datetime.now(timezone.utc)-timedelta(hours=24))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    df = df.drop('item_id', axis=1)\n",
    "    df['date'] = pd.to_datetime(df['date'], format=\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    df['date'] = df['date']+timedelta(hours=8)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_time(model, timetoday, best_time, dynamodb=None):\n",
    "    if not dynamodb:\n",
    "        dynamodb = boto3.resource('dynamodb')\n",
    "\n",
    "    table = dynamodb.Table('BestBillTime')\n",
    "    response = table.put_item(\n",
    "       Item={\n",
    "            'mt_category': model,\n",
    "            'forecast_date': timetoday,\n",
    "            'best_time': str(best_time)\n",
    "        }\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_pred()\n",
    "df = transform(df)\n",
    "sns.lineplot(x='date', y='p50', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_time = {}\n",
    "best_idx = df['p50'].idxmax()\n",
    "best_time, best_value = df.iloc[best_idx].date, df.iloc[best_idx].p50\n",
    "print(best_time, best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timetoday = datetime.today().strftime('%Y-%m-%d')\n",
    "put_time(model, timetoday, best_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tEnd = time.time()\n",
    "print (\"Spent %f minutes\" % ((tEnd - tStart)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
