{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you collect new data, you may want to use it to generate new forecasts. Forecast does not automatically retrain a predictor when you import an updated dataset, but you can use an existing predictor to generate forecasts with the updated data. For instance, if you collect daily sales data and want to include new datapoints in your forecast, you could import the updated data and use it to generate a forecast without training a new predictor. If, however, you want your predictor to be trained off of the new data, you must create a new predictor.\n",
    "* To generate a forecast off of new data:\n",
    "1. Upload the updated CSV file to an Amazon S3 bucket. The updated CSV should still contain all of your existing data.\n",
    "2. Create a dataset import job with the new data. The most recent import job is the one that forecasts are generated off of.\n",
    "3. Create a new forecast using the existing predictor.\n",
    "4. Retreieve the forecast as usual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import util\n",
    "import time\n",
    "import boto3\n",
    "import awswrangler as wr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "model = 'schedule'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tStart = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(region_name='us-east-1') \n",
    "forecast = session.client(service_name='forecast') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "TIMESTAMP_FORMAT = \"yyyy-MM-dd hh:mm:ss\"\n",
    "# Naming\n",
    "project = 'bill_scs_rate_' + model\n",
    "bucket_name = 'sagemaker-us-east-1-123456'\n",
    "key = 'puretech_data/' + model + '.csv'\n",
    "s3DataPath = \"s3://\"+bucket_name+\"/\"+key\n",
    "# Existing ARN\n",
    "role_arn = 'arn:aws:iam::123456:role/PuretechBillSuccessRateForecast'\n",
    "datasetArn = 'arn:aws:forecast:us-east-1:123456:dataset/bill_scs_rate_' + model + '_ds'\n",
    "predictorArn = 'arn:aws:forecast:us-east-1:123456:predictor/bill_scs_rate_' + model + '_predictor'\n",
    "forecastArn = 'arn:aws:forecast:us-east-1:123456:forecast/bill_scs_rate_' + model + '_forecast'\n",
    "forecastExportJobArn = 'arn:aws:forecast:us-east-1:123456:forecast-export-job/bill_scs_rate_' + model + '_forecast/export'\n",
    "datasetImportJobDeleteArn = forecast.describe_predictor(PredictorArn=predictorArn)['DatasetImportJobArns']\n",
    "# Service create\n",
    "timetoday = datetime.today().strftime('%Y-%m-%d').replace('-','_')\n",
    "datasetImportJobName = 'EP_DSIMPORT_JOB_TARGET_' + timetoday\n",
    "forecastName = project + '_forecast'\n",
    "forecastExportName = 'export'\n",
    "outputPath='s3://'+bucket_name+'/forecast_output/'+model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Import Job\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create import job name with timestamp\n",
    "ds_import_job_response=forecast.create_dataset_import_job(DatasetImportJobName=datasetImportJobName,\n",
    "                                                          DatasetArn=datasetArn,\n",
    "                                                          DataSource= {\n",
    "                                                              \"S3Config\" : {\n",
    "                                                                 \"Path\":s3DataPath,\n",
    "                                                                 \"RoleArn\": role_arn\n",
    "                                                              } \n",
    "                                                          },\n",
    "                                                          TimestampFormat=TIMESTAMP_FORMAT\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_import_job_arn=ds_import_job_response['DatasetImportJobArn']\n",
    "print(ds_import_job_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_indicator = util.StatusIndicator()\n",
    "\n",
    "while True:\n",
    "    status = forecast.describe_dataset_import_job(DatasetImportJobArn=ds_import_job_arn)['Status']\n",
    "    status_indicator.update(status)\n",
    "    if status in ('ACTIVE', 'CREATE_FAILED'): break\n",
    "    time.sleep(10)\n",
    "\n",
    "status_indicator.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete existing first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.wait_till_delete(lambda: forecast.delete_forecast_export_job(ForecastExportJobArn = forecastExportJobArn))\n",
    "util.wait_till_delete(lambda: forecast.delete_forecast(ForecastArn = forecastArn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_forecast_response=forecast.create_forecast(ForecastName=forecastName,\n",
    "                                                  PredictorArn=predictorArn)\n",
    "forecastArn = create_forecast_response['ForecastArn']\n",
    "print(forecastArn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_indicator = util.StatusIndicator()\n",
    "\n",
    "while True:\n",
    "    status = forecast.describe_forecast(ForecastArn=forecastArn)['Status']\n",
    "    status_indicator.update(status)\n",
    "    if status in ('ACTIVE', 'CREATE_FAILED'): break\n",
    "    time.sleep(10)\n",
    "\n",
    "status_indicator.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Forecast Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_export_response = forecast.create_forecast_export_job(\n",
    "                                             ForecastExportJobName = forecastExportName,\n",
    "                                             ForecastArn=forecastArn, \n",
    "                                             Destination = {\n",
    "                                                \"S3Config\" : {\n",
    "                                                    \"Path\":outputPath,\n",
    "                                                    \"RoleArn\": role_arn\n",
    "                                                } \n",
    "                                             }\n",
    "                                           )\n",
    "forecastExportJobArn = forecast_export_response['ForecastExportJobArn']\n",
    "print(forecastExportJobArn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_indicator = util.StatusIndicator()\n",
    "\n",
    "while True:\n",
    "    status = forecast.describe_forecast_export_job(ForecastExportJobArn=forecastExportJobArn)['Status']\n",
    "    status_indicator.update(status)\n",
    "    if status in ('ACTIVE', 'CREATE_FAILED'): break\n",
    "    time.sleep(10)\n",
    "\n",
    "status_indicator.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 to DynamoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pred():\n",
    "    bucket = sagemaker.Session().default_bucket()\n",
    "    prefix = 'forecast_output/' + model \n",
    "    path = f's3://{bucket}/{prefix}'   \n",
    "    suffix = 'part0.csv'    \n",
    "    df = wr.s3.read_csv(path=path, path_suffix=suffix, last_modified_begin=datetime.now(timezone.utc)-timedelta(hours=24))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    df = df.drop('item_id', axis=1)\n",
    "    df['date'] = pd.to_datetime(df['date'], format=\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    df['date'] = df['date']+timedelta(hours=8)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_time(model, timetoday, best_time, dynamodb=None):\n",
    "    if not dynamodb:\n",
    "        dynamodb = boto3.resource('dynamodb')\n",
    "\n",
    "    table = dynamodb.Table('BestBillTime')\n",
    "    response = table.put_item(\n",
    "       Item={\n",
    "            'mt_category': model,\n",
    "            'forecast_date': timetoday,\n",
    "            'best_time': str(best_time)\n",
    "        }\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_pred()\n",
    "df = transform(df)\n",
    "sns.lineplot(x='date', y='p50', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = df['p50'].idxmax()\n",
    "best_time, best_value = df.iloc[best_idx].date, df.iloc[best_idx].p50\n",
    "print(best_time, best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timetoday = datetime.today().strftime('%Y-%m-%d')\n",
    "put_time(model, timetoday, best_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tEnd = time.time()\n",
    "print (\"Spent %f minutes\" % ((tEnd - tStart)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
